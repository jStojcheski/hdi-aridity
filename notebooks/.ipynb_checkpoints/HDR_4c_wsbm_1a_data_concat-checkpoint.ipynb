{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDR: Weighted Stochastic Block Model (WSBM) data concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2010, 2016+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set input/output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = 'sparse/exp_0.5'\n",
    "\n",
    "data_in = f'../data/HDR_4c_wsbm/00_raw/{settings}'\n",
    "# pprint(sorted(list(os.listdir(data_in))))\n",
    "\n",
    "data_out = f'../data/HDR_4c_wsbm/01_merged/{settings}'\n",
    "if not os.path.exists(data_out):\n",
    "    os.makedirs(data_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set columns | <font style=\"color: #FF0000;\">Some DataFrame(s) may have already been sorted!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 6, 11, 16, 2, 7, 12, 17, 3, 8, 13, 18, 4, 9, 14, 19, 5, 10, 15, 20]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list()\n",
    "\n",
    "for i in range(5):\n",
    "    columns += list(np.arange(i, 20, 5) + 1)\n",
    "\n",
    "columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dfs = dict()\n",
    "logevd_dfs = dict()\n",
    "\n",
    "for file in sorted(os.listdir(data_in)):\n",
    "    info = file.split('_')\n",
    "    year = int(info[0])\n",
    "    tag  = info[1].split('.')[0]\n",
    "    \n",
    "    if tag == 'labels':\n",
    "        if year not in labels_dfs.keys():\n",
    "            labels_dfs[year] = pd.read_csv(f'{data_in}/{file}', header=None)\n",
    "        else:\n",
    "            labels_dfs[year] = pd.concat([labels_dfs[year], pd.read_csv(f'{data_in}/{file}', header=None)], axis=1)\n",
    "#             labels_dfs[year] = labels_dfs[year].reindex()\n",
    "            \n",
    "    if tag == 'logevidence':\n",
    "        if year not in logevd_dfs.keys():\n",
    "            logevd_dfs[year] = pd.read_csv(f'{data_in}/{file}', header=None)\n",
    "        else:\n",
    "            logevd_dfs[year] = pd.concat([logevd_dfs[year], pd.read_csv(f'{data_in}/{file}', header=None)], axis=1)\n",
    "#             logevd_dfs[year] = logevd_dfs[year].reindex()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-index data axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_df = pd.read_csv('../data/HDR_4a_graph_formation/mean/l1_2010.csv', index_col='Country')\n",
    "# labels_dfs[2010].index = temp_df.index\n",
    "# labels_dfs[2010].columns = np.arange(labels_dfs[2010].shape[1]) + 1\n",
    "\n",
    "# logevd_dfs[2010].index = ['Log-Likelihood']\n",
    "# logevd_dfs[2010].columns = np.arange(logevd_dfs[2010].shape[1]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    temp_df = pd.read_csv(f'../data/HDR_4a_graph_formation/mean/l1_{year}.csv', index_col='Country')\n",
    "    \n",
    "    labels_dfs[year].index   = temp_df.index\n",
    "    labels_dfs[year].columns = columns\n",
    "    labels_dfs[year] = labels_dfs[year].reindex(sorted(labels_dfs[year].columns), axis=1)\n",
    "    \n",
    "    logevd_dfs[year].index   = ['Log-Likelihood']\n",
    "    logevd_dfs[year].columns = columns\n",
    "    logevd_dfs[year] = logevd_dfs[year].reindex(sorted(logevd_dfs[year].columns), axis=1)\n",
    "    \n",
    "    del(temp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output data to csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    labels_dfs[year].to_csv(f'{data_out}/{year}_labels.csv', index_label='Country')\n",
    "    logevd_dfs[year].to_csv(f'{data_out}/{year}_logevd.csv', index_label='Measure')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

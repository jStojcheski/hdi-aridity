{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDR: <code>npy</code> concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = 'full'  # ['full', 'sparse']\n",
    "\n",
    "std_X = 'z_score'\n",
    "std_t = 'max_min'\n",
    "\n",
    "year_s = 2010\n",
    "year_f = 2016\n",
    "period = f'{year_s}_{year_f}'\n",
    "\n",
    "# years = pd.Series(np.arange(year_s, year_f+1))\n",
    "year  = 2011\n",
    "\n",
    "n_attrs  = 97      # number of attributes\n",
    "n_hidden = 12      # number of neurons in the hidden layer\n",
    "n_iters  = 100000  # number of iterations per start\n",
    "n_starts = 20      # number of random starts\n",
    "l_rate   = 1       # learning rate  (0 < l_rate <= 1)\n",
    "\n",
    "modulo = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set input/output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = f'{conn}/{std_X}__{std_t}/{period}/{year}/{n_iters}i_{n_hidden}h_{l_rate}l'\n",
    "\n",
    "data_in  = f'../data/HDR_3_nn_1a_init_training/{settings}'\n",
    "data_out = f'../data/HDR_3_nn_2a_concat_npy/{settings}'\n",
    "\n",
    "if not os.path.exists(data_out):\n",
    "    os.makedirs(data_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(os.listdir(data_in))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B_x = np.stack([np.load(f'{data_in}/{file}')\n",
    "#                 for file in files\n",
    "#                 if 'B_x_res.npy' in file])\n",
    "# np.save(f'{data_out}/B_x', B_x)\n",
    "# print('B_x:', B_x.shape)\n",
    "# del(B_x)\n",
    "\n",
    "# B_h = np.stack([np.load(f'{data_in}/{file}')\n",
    "#                 for file in files\n",
    "#                 if 'B_h_res.npy' in file])\n",
    "# np.save(f'{data_out}/B_h', B_h)\n",
    "# print('B_h:', B_h.shape)\n",
    "# del(B_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W_x = np.stack([np.load(f'{data_in}/{file}')\n",
    "#                 for file in files\n",
    "#                 if 'W_x_res.npy' in file])\n",
    "# np.save(f'{data_out}/W_x', W_x)\n",
    "# print('W_x:', W_x.shape)\n",
    "# del(W_x)\n",
    "\n",
    "\n",
    "# W_h = np.stack([np.load(f'{data_in}/{file}')\n",
    "#                 for file in files\n",
    "#                 if 'W_h_res.npy' in file])\n",
    "# np.save(f'{data_out}/W_h', W_h)\n",
    "# print('W_h:', W_h.shape)\n",
    "# del(W_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.stack([np.load(f'{data_in}/{file}')\n",
    "              for file in files\n",
    "              if 'y_res.npy' in file])\n",
    "np.save(f'{data_out}/y', y)\n",
    "print('y:  ', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutual countries HDR (2010-2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntr = pd.read_csv(f'../data/HDR_mutual_attributes_and_countries/countries_{period}.csv',\n",
    "                   header=None)\n",
    "cntr = list(cntr[0])\n",
    "\n",
    "print('Total countries:', len(cntr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate loss function; Output data to csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv(f'../data/HDR_2a_{std_t}_year/{year}.csv', index_col='Country')\n",
    "t = t.loc[cntr]  # mutual countries\n",
    "t = t[t.notna()['Human Development Index (HDI)'] == True]\n",
    "t = t['Human Development Index (HDI)'].values  # target values\n",
    "\n",
    "C = np.zeros((y.shape[0], y.shape[2]))\n",
    "\n",
    "for s in range(y.shape[0]):\n",
    "    C[s, :] = np.average((np.subtract(y[s, :, :].T, t).T ** 2) / 2, axis=0)\n",
    "    \n",
    "np.save(f'{data_out}/C', C)\n",
    "print('C:  ', C.shape)\n",
    "\n",
    "del(C)\n",
    "del(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiply the weights between the layers; Output data to csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = sorted(list(set([file.split('_')[0] for file in files])))\n",
    "n_starts = len(prefixes)\n",
    "\n",
    "W = np.ndarray((n_starts, n_attrs, n_iters))\n",
    "\n",
    "for prefix in prefixes:\n",
    "    s = prefixes.index(prefix)\n",
    "    print(f'========== {s+1}/{n_starts} ==========')\n",
    "\n",
    "    W_x = np.load(f'{data_in}/{prefix}_W_x_res.npy')\n",
    "    W_h = np.load(f'{data_in}/{prefix}_W_h_res.npy')\n",
    "    # print('W_x:', W_x.shape)\n",
    "    # print('W_h:', W_h.shape)\n",
    "\n",
    "    for i in range(n_iters):\n",
    "        if (i+1) % modulo == 0:\n",
    "            print(f'{year} | {s+1}/{n_starts} | Iteration {i+1}/{n_iters}...',\n",
    "                  end=' ')\n",
    "            \n",
    "        W[s, :, i] = np.dot(W_x[:, :, i], W_h[:, i])\n",
    "        \n",
    "        if (i+1) % modulo == 0:\n",
    "            print('Done!')\n",
    "        \n",
    "    print('\\n')\n",
    "    \n",
    "print('Saving weights...', end=' ')\n",
    "np.save(f'{data_out}/W', W)\n",
    "print('Done!')\n",
    "print('W:  ', W.shape)\n",
    "\n",
    "del(W)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
